{"cells": [{"cell_type": "markdown", "metadata": {}, "source": ["TechVidvan Vehicle counting and Classification"]}, {"cell_type": "markdown", "metadata": {}, "source": ["Import necessary packages"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["import cv2\n", "import csv\n", "import collections\n", "import numpy as np\n", "from tracker import *"]}, {"cell_type": "markdown", "metadata": {}, "source": ["Initialize Tracker"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["tracker = EuclideanDistTracker()"]}, {"cell_type": "markdown", "metadata": {}, "source": ["Initialize the videocapture object"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["cap = cv2.VideoCapture('video.mp4')\n", "input_size = 320"]}, {"cell_type": "markdown", "metadata": {}, "source": ["Detection confidence threshold"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["confThreshold =0.2\n", "nmsThreshold= 0.2"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["font_color = (0, 0, 255)\n", "font_size = 0.5\n", "font_thickness = 2"]}, {"cell_type": "markdown", "metadata": {}, "source": ["Middle cross line position"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["middle_line_position = 225   \n", "up_line_position = middle_line_position - 15\n", "down_line_position = middle_line_position + 15"]}, {"cell_type": "markdown", "metadata": {}, "source": ["Store Coco Names in a list"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["classesFile = \"coco.names\"\n", "classNames = open(classesFile).read().strip().split('\\n')\n", "print(classNames)\n", "print(len(classNames))"]}, {"cell_type": "markdown", "metadata": {}, "source": ["class index for our required detection classes"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["required_class_index = [2, 3, 5, 7]"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["detected_classNames = []"]}, {"cell_type": "markdown", "metadata": {}, "source": [" Model Files"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["modelConfiguration = 'yolov3-320.cfg'\n", "modelWeigheights = 'yolov3-320.weights'"]}, {"cell_type": "markdown", "metadata": {}, "source": ["configure the network model"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["net = cv2.dnn.readNetFromDarknet(modelConfiguration, modelWeigheights)"]}, {"cell_type": "markdown", "metadata": {}, "source": ["Configure the network backend"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["net.setPreferableBackend(cv2.dnn.DNN_BACKEND_CUDA)\n", "net.setPreferableTarget(cv2.dnn.DNN_TARGET_CUDA)"]}, {"cell_type": "markdown", "metadata": {}, "source": ["Define random colour for each class"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["np.random.seed(42)\n", "colors = np.random.randint(0, 255, size=(len(classNames), 3), dtype='uint8')"]}, {"cell_type": "markdown", "metadata": {}, "source": ["Function for finding the center of a rectangle"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["def find_center(x, y, w, h):\n", "    x1=int(w/2)\n", "    y1=int(h/2)\n", "    cx = x+x1\n", "    cy=y+y1\n", "    return cx, cy\n", "    \n", "# List for store vehicle count information\n", "temp_up_list = []\n", "temp_down_list = []\n", "up_list = [0, 0, 0, 0]\n", "down_list = [0, 0, 0, 0]"]}, {"cell_type": "markdown", "metadata": {}, "source": ["Function for count vehicle"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["def count_vehicle(box_id, img):\n", "    x, y, w, h, id, index = box_id\n\n", "    # Find the center of the rectangle for detection\n", "    center = find_center(x, y, w, h)\n", "    ix, iy = center\n", "    \n", "    # Find the current position of the vehicle\n", "    if (iy > up_line_position) and (iy < middle_line_position):\n", "        if id not in temp_up_list:\n", "            temp_up_list.append(id)\n", "    elif iy < down_line_position and iy > middle_line_position:\n", "        if id not in temp_down_list:\n", "            temp_down_list.append(id)\n", "            \n", "    elif iy < up_line_position:\n", "        if id in temp_down_list:\n", "            temp_down_list.remove(id)\n", "            up_list[index] = up_list[index]+1\n", "    elif iy > down_line_position:\n", "        if id in temp_up_list:\n", "            temp_up_list.remove(id)\n", "            down_list[index] = down_list[index] + 1\n\n", "    # Draw circle in the middle of the rectangle\n", "    cv2.circle(img, center, 2, (0, 0, 255), -1)  # end here\n", "    # print(up_list, down_list)"]}, {"cell_type": "markdown", "metadata": {}, "source": ["Function for finding the detected objects from the network output"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["def postProcess(outputs,img):\n", "    global detected_classNames \n", "    height, width = img.shape[:2]\n", "    boxes = []\n", "    classIds = []\n", "    confidence_scores = []\n", "    detection = []\n", "    for output in outputs:\n", "        for det in output:\n", "            scores = det[5:]\n", "            classId = np.argmax(scores)\n", "            confidence = scores[classId]\n", "            if classId in required_class_index:\n", "                if confidence > confThreshold:\n", "                    # print(classId)\n", "                    w,h = int(det[2]*width) , int(det[3]*height)\n", "                    x,y = int((det[0]*width)-w/2) , int((det[1]*height)-h/2)\n", "                    boxes.append([x,y,w,h])\n", "                    classIds.append(classId)\n", "                    confidence_scores.append(float(confidence))\n\n", "    # Apply Non-Max Suppression\n", "    indices = cv2.dnn.NMSBoxes(boxes, confidence_scores, confThreshold, nmsThreshold)\n", "    # print(classIds)\n", "    for i in indices.flatten():\n", "        x, y, w, h = boxes[i][0], boxes[i][1], boxes[i][2], boxes[i][3]\n", "        # print(x,y,w,h)\n", "        color = [int(c) for c in colors[classIds[i]]]\n", "        name = classNames[classIds[i]]\n", "        detected_classNames.append(name)\n", "        # Draw classname and confidence score \n", "        cv2.putText(img,f'{name.upper()} {int(confidence_scores[i]*100)}%',\n", "                  (x, y-10), cv2.FONT_HERSHEY_SIMPLEX, 0.5, color, 1)\n\n", "        # Draw bounding rectangle\n", "        cv2.rectangle(img, (x, y), (x + w, y + h), color, 1)\n", "        detection.append([x, y, w, h, required_class_index.index(classIds[i])])\n\n", "    # Update the tracker for each object\n", "    boxes_ids = tracker.update(detection)\n", "    for box_id in boxes_ids:\n", "        count_vehicle(box_id, img)"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["def realTime():\n", "    while True:\n", "        success, img = cap.read()\n", "        img = cv2.resize(img,(0,0),None,0.5,0.5)\n", "        ih, iw, channels = img.shape\n", "        blob = cv2.dnn.blobFromImage(img, 1 / 255, (input_size, input_size), [0, 0, 0], 1, crop=False)\n\n", "        # Set the input of the network\n", "        net.setInput(blob)\n", "        layersNames = net.getLayerNames()\n", "        outputNames = [(layersNames[i[0] - 1]) for i in net.getUnconnectedOutLayers()]\n", "        # Feed data to the network\n", "        outputs = net.forward(outputNames)\n", "    \n", "        # Find the objects from the network output\n", "        postProcess(outputs,img)\n\n", "        # Draw the crossing lines\n", "        cv2.line(img, (0, middle_line_position), (iw, middle_line_position), (255, 0, 255), 2)\n", "        cv2.line(img, (0, up_line_position), (iw, up_line_position), (0, 0, 255), 2)\n", "        cv2.line(img, (0, down_line_position), (iw, down_line_position), (0, 0, 255), 2)\n\n", "        # Draw counting texts in the frame\n", "        cv2.putText(img, \"Up\", (110, 20), cv2.FONT_HERSHEY_SIMPLEX, font_size, font_color, font_thickness)\n", "        cv2.putText(img, \"Down\", (160, 20), cv2.FONT_HERSHEY_SIMPLEX, font_size, font_color, font_thickness)\n", "        cv2.putText(img, \"Car:        \"+str(up_list[0])+\"     \"+ str(down_list[0]), (20, 40), cv2.FONT_HERSHEY_SIMPLEX, font_size, font_color, font_thickness)\n", "        cv2.putText(img, \"Motorbike:  \"+str(up_list[1])+\"     \"+ str(down_list[1]), (20, 60), cv2.FONT_HERSHEY_SIMPLEX, font_size, font_color, font_thickness)\n", "        cv2.putText(img, \"Bus:        \"+str(up_list[2])+\"     \"+ str(down_list[2]), (20, 80), cv2.FONT_HERSHEY_SIMPLEX, font_size, font_color, font_thickness)\n", "        cv2.putText(img, \"Truck:      \"+str(up_list[3])+\"     \"+ str(down_list[3]), (20, 100), cv2.FONT_HERSHEY_SIMPLEX, font_size, font_color, font_thickness)\n\n", "        # Show the frames\n", "        cv2.imshow('Output', img)\n", "        if cv2.waitKey(1) == ord('q'):\n", "            break\n\n", "    # Write the vehicle counting information in a file and save it\n", "    with open(\"data.csv\", 'w') as f1:\n", "        cwriter = csv.writer(f1)\n", "        cwriter.writerow(['Direction', 'car', 'motorbike', 'bus', 'truck'])\n", "        up_list.insert(0, \"Up\")\n", "        down_list.insert(0, \"Down\")\n", "        cwriter.writerow(up_list)\n", "        cwriter.writerow(down_list)\n", "    f1.close()\n", "    # print(\"Data saved at 'data.csv'\")\n", "    # Finally realese the capture object and destroy all active windows\n", "    cap.release()\n", "    cv2.destroyAllWindows()"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["image_file = 'vehicle classification-image02.png'\n", "def from_static_image(image):\n", "    img = cv2.imread(image)\n", "    blob = cv2.dnn.blobFromImage(img, 1 / 255, (input_size, input_size), [0, 0, 0], 1, crop=False)\n\n", "    # Set the input of the network\n", "    net.setInput(blob)\n", "    layersNames = net.getLayerNames()\n", "    outputNames = [(layersNames[i[0] - 1]) for i in net.getUnconnectedOutLayers()]\n", "    # Feed data to the network\n", "    outputs = net.forward(outputNames)\n\n", "    # Find the objects from the network output\n", "    postProcess(outputs,img)\n\n", "    # count the frequency of detected classes\n", "    frequency = collections.Counter(detected_classNames)\n", "    print(frequency)\n", "    # Draw counting texts in the frame\n", "    cv2.putText(img, \"Car:        \"+str(frequency['car']), (20, 40), cv2.FONT_HERSHEY_SIMPLEX, font_size, font_color, font_thickness)\n", "    cv2.putText(img, \"Motorbike:  \"+str(frequency['motorbike']), (20, 60), cv2.FONT_HERSHEY_SIMPLEX, font_size, font_color, font_thickness)\n", "    cv2.putText(img, \"Bus:        \"+str(frequency['bus']), (20, 80), cv2.FONT_HERSHEY_SIMPLEX, font_size, font_color, font_thickness)\n", "    cv2.putText(img, \"Truck:      \"+str(frequency['truck']), (20, 100), cv2.FONT_HERSHEY_SIMPLEX, font_size, font_color, font_thickness)"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["    cv2.imshow(\"image\", img)\n", "    cv2.waitKey(0)\n\n", "    # save the data to a csv file\n", "    with open(\"static-data.csv\", 'a') as f1:\n", "        cwriter = csv.writer(f1)\n", "        cwriter.writerow([image, frequency['car'], frequency['motorbike'], frequency['bus'], frequency['truck']])\n", "    f1.close()"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["if __name__ == '__main__':\n", "    # realTime()\n", "    from_static_image(image_file)"]}], "metadata": {"kernelspec": {"display_name": "Python 3", "language": "python", "name": "python3"}, "language_info": {"codemirror_mode": {"name": "ipython", "version": 3}, "file_extension": ".py", "mimetype": "text/x-python", "name": "python", "nbconvert_exporter": "python", "pygments_lexer": "ipython3", "version": "3.6.4"}}, "nbformat": 4, "nbformat_minor": 2}